{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project_MSCA Big Data and Text Analytics_Yuxiao Sun_455136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pig Script for Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGISTER hdfs:///jar/elephant-bird/json-simple-1.1.1.jar;\n",
    "REGISTER hdfs:///jar/elephant-bird/elephant-bird-core-4.6-SNAPSHOT.jar;\n",
    "REGISTER hdfs:///jar/elephant-bird/elephant-bird-pig-4.6-SNAPSHOT.jar;\n",
    "REGISTER hdfs:///jar/elephant-bird/elephant-bird-hadoop-compat-4.6-SNAPSHOT.jar;\n",
    "REGISTER hdfs:///jar/tutorial.jar;\n",
    "\n",
    "A = load '/user/kadochnikov/twitter_full/' USING com.twitter.elephantbird.pig.load.JsonLoader('-nestedLoad') as tweet;\n",
    "B = FOREACH A GENERATE\n",
    "    (CHARARRAY)tweet#'id' as t_id,\n",
    "    (CHARARRAY)tweet#'lang' AS t_lang,\n",
    "    (CHARARRAY)tweet#'created_at' AS t_created_at,\n",
    "    (CHARARRAY)tweet#'text' AS t_text,\n",
    "    (INT)tweet#'retweet_count' as t_retweet_n,\n",
    "    (INT)tweet#'favorite_count' as t_favorite_n,\n",
    "    tweet#'user' as user,\n",
    "    tweet#'retweeted_status' as retweet\n",
    "    ;\n",
    "\n",
    "C = FOREACH B GENERATE\n",
    "    t_id,\n",
    "    t_lang,\n",
    "    t_created_at,\n",
    "    t_text,\n",
    "    t_retweet_n,\n",
    "    t_favorite_n,\n",
    "\n",
    "    (CHARARRAY)user#'screen_name' as u_screen_name,\n",
    "    (CHARARRAY)user#'name' as u_name,\n",
    "    (CHARARRAY)user#'location' as u_location,\n",
    "    (CHARARRAY)user#'description' as u_description,\n",
    "    (INT)user#'followers_count' as u_follower_n,\n",
    "    (INT)user#'friends_count' as u_friend_n,\n",
    "    (INT)user#'listed_count' as u_listed_n,\n",
    "    (INT)user#'favourites_count' as u_favorite_n,\n",
    "    (INT)user#'statuses_count' as u_statuse_n,\n",
    "    (CHARARRAY)user#'created_at' AS u_created_at,\n",
    "    (CHARARRAY)user#'time_zone' AS u_time_zone,\n",
    "\n",
    "    (CHARARRAY)retweet#'id' as rt_id,\n",
    "    (CHARARRAY)retweet#'created_at' AS rt_created_at,\n",
    "    (INT)retweet#'retweet_count' as rt_retweet_n,\n",
    "    (INT)retweet#'favorite_count' as rt_favorite_n,\n",
    "    retweet#'user' as retweet_user\n",
    "    ;\n",
    "\n",
    "D = FOREACH C GENERATE\n",
    "    t_id,\n",
    "    t_lang,\n",
    "    t_created_at,\n",
    "    REPLACE(REPLACE(REPLACE(t_text, '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS t_text,\n",
    "    t_retweet_n,\n",
    "    t_favorite_n,\n",
    "    REPLACE(REPLACE(REPLACE(u_screen_name, '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS u_screen_name,\n",
    "    REPLACE(REPLACE(REPLACE(u_name, '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS u_name,\n",
    "    REPLACE(REPLACE(REPLACE(u_location, '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS u_location,\n",
    "    REPLACE(REPLACE(REPLACE(u_description, '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS u_description,\n",
    "    u_follower_n,\n",
    "    u_friend_n,\n",
    "    u_listed_n,\n",
    "    u_favorite_n,\n",
    "    u_statuse_n,\n",
    "    u_created_at,\n",
    "    u_time_zone,\n",
    "    rt_id,\n",
    "    rt_created_at,\n",
    "    rt_retweet_n,\n",
    "    rt_favorite_n,\n",
    "\n",
    "    REPLACE(REPLACE(REPLACE((CHARARRAY)retweet_user#'screen_name', '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS ru_screen_name,\n",
    "    REPLACE(REPLACE(REPLACE((CHARARRAY)retweet_user#'name', '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS ru_name,    \n",
    "    REPLACE(REPLACE(REPLACE((CHARARRAY)retweet_user#'location', '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS ru_location,\n",
    "    REPLACE(REPLACE(REPLACE((CHARARRAY)retweet_user#'description', '\\r\\n', ' '), '\\r', ' '), '\\n', ' ') AS ru_description,\n",
    "    (INT)retweet_user#'followers_count' as ru_follower_n,\n",
    "    (INT)retweet_user#'friends_count' as ru_friend_n,\n",
    "    (INT)retweet_user#'listed_count' as ru_listed_n,\n",
    "    (INT)retweet_user#'favourites_count' as ru_favorite_n,\n",
    "    (INT)retweet_user#'statuses_count' as ru_statuse_n,\n",
    "    (CHARARRAY)retweet_user#'created_at' AS ru_created_at,\n",
    "    (CHARARRAY)retweet_user#'time_zone' AS ru_time_zone\n",
    "    ; \n",
    "\n",
    "E = FILTER D BY (t_text matches '(?i).*uchicago.*' or t_text matches '(?i).*university of chicago.*' or t_text matches '(?i).*harvard.*' or t_text matches '(?i).*stanford.*' or t_text matches '(?i).*princeton.*' or t_text matches '(?i).*columbia.*' or t_text matches '(?i).*yale.*');\n",
    "    \n",
    "SET hcat.bin /usr/bin/hcat;\n",
    "sql drop table yx1;\n",
    "sql create table yx1 (t_id string, t_lang string, t_created_at string, t_text string, t_retweet_n int, t_favorite_n int, u_screen_name string, u_name string, u_location string, u_description string, u_follower_n int, u_friend_n int, u_listed_n int, u_favorite_n int, u_statuse_n int, u_created_at string, u_time_zone string, rt_id string, rt_created_at string, rt_retweet_n int, rt_favorite_n int, ru_screen_name string, ru_name string, ru_location string, ru_description string, ru_follower_n int, ru_friend_n int, ru_listed_n int, ru_favorite_n int, ru_statuse_n int, ru_created_at string, ru_time_zone string);\n",
    "STORE E INTO 'yx1' USING org.apache.hive.hcatalog.pig.HCatStorer();\n",
    "\n",
    "rmf /user/yuxiao/msca\n",
    "STORE E INTO '/user/yuxiao/msca';\n",
    "\n",
    "reduced = FOREACH (GROUP E BY RANDOM()) GENERATE FLATTEN(E);\n",
    "rmf /user/yuxiao/msca\n",
    "STORE reduced INTO '/user/yuxiao/msca';\n",
    "\n",
    "hadoop fs -copyToLocal /user/yuxiao/msca /home/yuxiao/msca\n",
    "\n",
    "Type=File and Value=/user/hive/hive-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,23,24,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('top5t.csv') #tweets data (tweets without rt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=pd.read_csv('top5rt.csv') #retweets data (tweets with rt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.rename(columns={col: col.split('.')[1] for col in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=df2.rename(columns={col: col.split('.')[1] for col in df2.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"t_text\"]=df[\"t_text\"].str.lower() #lower the tweets text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2[\"t_text\"]=df2[\"t_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df[df.t_lang=='en'].reset_index(drop=True) #only keep english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=df2[df2.t_lang=='en'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626226"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_id              626226\n",
       "t_lang            626226\n",
       "t_created_at      626226\n",
       "t_text            626226\n",
       "t_retweet_n       626226\n",
       "t_favorite_n      626226\n",
       "u_screen_name     626226\n",
       "u_name            626161\n",
       "u_location        424101\n",
       "u_description     541251\n",
       "u_follower_n      626226\n",
       "u_friend_n        626226\n",
       "u_listed_n        626226\n",
       "u_favorite_n      626226\n",
       "u_statuse_n       626226\n",
       "u_created_at      626226\n",
       "u_time_zone       396414\n",
       "rt_id                  0\n",
       "rt_created_at          0\n",
       "rt_retweet_n           0\n",
       "rt_favorite_n          0\n",
       "ru_screen_name         0\n",
       "ru_name                0\n",
       "ru_location            0\n",
       "ru_description         0\n",
       "ru_follower_n          0\n",
       "ru_friend_n            0\n",
       "ru_listed_n            0\n",
       "ru_favorite_n          0\n",
       "ru_statuse_n           0\n",
       "ru_created_at          0\n",
       "ru_time_zone           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() #tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"t_created_at\"]=pd.to_datetime(df[\"t_created_at\"]) #change created_at to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efb8e5a6710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1zyYmJlZ1zyYmJlZ1/4/F2ozcCiSz5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efba8a7a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df[\"t_created_at\"].hist(xlabelsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a copy of df\n",
    "dft=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_id              608872\n",
       "t_lang            608872\n",
       "t_created_at      608872\n",
       "t_text            608872\n",
       "t_retweet_n       608872\n",
       "t_favorite_n      608872\n",
       "u_screen_name     608872\n",
       "u_name            608847\n",
       "u_location        402436\n",
       "u_description     515089\n",
       "u_follower_n      608872\n",
       "u_friend_n        608872\n",
       "u_listed_n        608872\n",
       "u_favorite_n      608872\n",
       "u_statuse_n       608872\n",
       "u_created_at      608872\n",
       "u_time_zone       364893\n",
       "rt_id             608872\n",
       "rt_created_at     608872\n",
       "rt_retweet_n      608872\n",
       "rt_favorite_n     608872\n",
       "ru_screen_name    608872\n",
       "ru_name           608863\n",
       "ru_location       475390\n",
       "ru_description    591111\n",
       "ru_follower_n     608872\n",
       "ru_friend_n       608872\n",
       "ru_listed_n       608872\n",
       "ru_favorite_n     608872\n",
       "ru_statuse_n      608872\n",
       "ru_created_at     608872\n",
       "ru_time_zone      536731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count() #retweets dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a binary indicator for each university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniDummy(df,text,keys):\n",
    "    for key in keys:\n",
    "        df[key]=pd.get_dummies(df[text].str.contains(key, na=False))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically there are strict and loose filters for each univeristy.\n",
    "Harvard could be filtered by \"harvard\" or by \"harvard university\", and the former would contains much more results since people in twitter rarely refere harvard by its full name.\n",
    "For I have developed two sets of filters--one based on my knowledge of how universities are refered, and another one that uses the most restirctive reference to all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)The prefered filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I use columbia university instead of columbia to filter cu\n",
    "#otherwise cu would be confounded with british columbia, columbia city at missouri, etc.\n",
    "#For other universities I find the shorter name most useful\n",
    "uniDummy(df,\"t_text\",[\"uchicago|university of chicago\",\"harvard\",\"stanford\",\"princeton\",\"columbia university\",\"yale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniDummy(df2,\"t_text\",[\"uchicago|university of chicago\",\"harvard\",\"stanford\",\"princeton\",\"columbia university\",\"yale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_id', 't_lang', 't_created_at', 't_text', 't_retweet_n',\n",
       "       't_favorite_n', 'u_screen_name', 'u_name', 'u_location',\n",
       "       'u_description', 'u_follower_n', 'u_friend_n', 'u_listed_n',\n",
       "       'u_favorite_n', 'u_statuse_n', 'u_created_at', 'u_time_zone', 'rt_id',\n",
       "       'rt_created_at', 'rt_retweet_n', 'rt_favorite_n', 'ru_screen_name',\n",
       "       'ru_name', 'ru_location', 'ru_description', 'ru_follower_n',\n",
       "       'ru_friend_n', 'ru_listed_n', 'ru_favorite_n', 'ru_statuse_n',\n",
       "       'ru_created_at', 'ru_time_zone', 'uchicago|university of chicago',\n",
       "       'harvard', 'stanford', 'princeton', 'columbia university', 'yale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text']=df['t_text'] #make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['text']=df2['t_text'] #make a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmString(df,text,keys):\n",
    "    for key in keys:\n",
    "        df[text]=df[text].str.replace(key,'')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmString(df,\"t_text\",[\"uchicago\", \"university of chicago\",\"harvard\",\"stanford\",\"princeton\",\"columbia university\",\"yale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmString(df2,\"t_text\",[\"uchicago\", \"university of chicago\",\"harvard\",\"stanford\",\"princeton\",\"columbia university\",\"yale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sum']=df[\"uchicago|university of chicago\"]+df[\"harvard\"]+df[\"stanford\"]+df[\"princeton\"]+df[\"columbia university\"]+df[\"yale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['sum']=df2[\"uchicago|university of chicago\"]+df2[\"harvard\"]+df2[\"stanford\"]+df2[\"princeton\"]+df2[\"columbia university\"]+df2[\"yale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[df[\"sum\"]==1].reset_index(drop=True) #only keep tweets related to the top5 universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=df2[df2[\"sum\"]==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys=[\"columbia university\",\"harvard\",\"princeton\",\"stanford\",\"uchicago|university of chicago\",\"yale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columbia university                 8131.0\n",
       "harvard                           240992.0\n",
       "princeton                          88694.0\n",
       "stanford                          229106.0\n",
       "uchicago|university of chicago     17905.0\n",
       "yale                               16473.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[keys].sum() #tweets distribution across universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columbia university                 6215.0\n",
       "harvard                           293673.0\n",
       "princeton                          55731.0\n",
       "stanford                          202707.0\n",
       "uchicago|university of chicago     15630.0\n",
       "yale                               16167.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[keys].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"uni\"]=df[\"columbia university\"]+df[\"harvard\"]*2+df[\"princeton\"]*3+df[\"stanford\"]*4+df[\"uchicago|university of chicago\"]*5+df[\"yale\"]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2[\"uni\"]=df2[\"columbia university\"]+df2[\"harvard\"]*2+df2[\"princeton\"]*3+df2[\"stanford\"]*4+df2[\"uchicago|university of chicago\"]*5+df2[\"yale\"]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    240992\n",
       "4.0    229106\n",
       "3.0     88694\n",
       "5.0     17905\n",
       "6.0     16473\n",
       "1.0      8131\n",
       "Name: uni, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uni\"].value_counts() #categorical representation of university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.The restrictive filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this filtering would create large downward bias for harvard, stanford, princeton and yale\n",
    "#since they are rarely referred by full name. I keep this for a test purpose\n",
    "uniDummy(dft,\"t_text\",[\"university of chicago\",\"harvard university\",\"stanford university\",\"princeton university\",\"columbia university\",\"yale university\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmString(dft,\"t_text\",[\"university of chicago\",\"harvard university\",\"stanford university\",\"princeton university\",\"columbia university\",\"yale university\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft['sum']=dft[\"university of chicago\"]+dft[\"harvard university\"]+dft[\"stanford university\"]+dft[\"princeton university\"]+dft[\"columbia university\"]+dft[\"yale university\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft=dft[dft[\"sum\"]==1].reset_index(drop=True) #only keep tweets related to the top5 universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyst=[\"columbia university\",\"harvard university\",\"princeton university\",\"stanford university\",\"university of chicago\",\"yale university\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columbia university       8223.0\n",
       "harvard university       18881.0\n",
       "princeton university      4247.0\n",
       "stanford university      10168.0\n",
       "university of chicago    10768.0\n",
       "yale university          11974.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[keyst].sum() #tweets distribution across universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft[\"uni\"]=dft[\"columbia university\"]+dft[\"harvard university\"]*2+dft[\"princeton university\"]*3+dft[\"stanford university\"]*4+dft[\"university of chicago\"]*5+dft[\"yale university\"]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    18881\n",
       "6.0    11974\n",
       "5.0    10768\n",
       "4.0    10168\n",
       "1.0     8223\n",
       "3.0     4247\n",
       "Name: uni, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[\"uni\"].value_counts() #categorical representation of university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word tokenizer UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')+get_stop_words('english')+['university','school','via','rt','study','go','take','would','will','could','can','may','got','get','u','say','do','dont','show']\n",
    "exclude = set(string.punctuation)\n",
    "exclude.update(['—','–','…', '📷', '😂','’',\"“\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in exclude])\n",
    "    tokens = [token for token in word_tokenize(text) if token not in stop]\n",
    "    wnl = WordNetLemmatizer()\n",
    "    wnltokens = [wnl.lemmatize(t) for t in tokens]\n",
    "    return wnltokens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 8000        # sample size\n",
    "replace = False  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601301"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dff=df.groupby('uni', as_index=False).apply(fn).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dff[\"t_text\"], dff[\"uni\"], test_size=8000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columbia university               8000.0\n",
       "harvard                           8000.0\n",
       "princeton                         8000.0\n",
       "stanford                          8000.0\n",
       "uchicago|university of chicago    8000.0\n",
       "yale                              8000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff[keys].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 0 ns, total: 11.3 s\n",
      "Wall time: 11.3 s\n",
      "(40000, 23380)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=3, tokenizer=tokenize_lemmatize, stop_words='english', ngram_range=(1,2))\n",
    "%time vectors_train = tfidf_vectorizer.fit_transform(X_train) #fit the vectorizer to tweets\n",
    "print(vectors_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mclf = MultinomialNB(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mclf2 = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclf.fit(vectors_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclf2.fit(vectors_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=mclf.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsdg=mclf2.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.745\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, predsdg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.85      0.77      0.81      1367\n",
      "        2.0       0.56      0.74      0.64      1263\n",
      "        3.0       0.68      0.70      0.69      1327\n",
      "        4.0       0.75      0.74      0.74      1377\n",
      "        5.0       0.82      0.73      0.77      1341\n",
      "        6.0       0.88      0.78      0.83      1325\n",
      "\n",
      "avg / total       0.76      0.74      0.75      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.82      0.81      0.81      1367\n",
      "        2.0       0.63      0.70      0.66      1263\n",
      "        3.0       0.71      0.71      0.71      1327\n",
      "        4.0       0.75      0.76      0.76      1377\n",
      "        5.0       0.80      0.76      0.78      1341\n",
      "        6.0       0.85      0.82      0.84      1325\n",
      "\n",
      "avg / total       0.76      0.76      0.76      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predsdg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=20):\n",
    "    labelid = list(classifier.classes_).index(classlabel)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n",
    "    for coef, feat in topn:\n",
    "        print (classlabel, feat, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['columbia university',\n",
       " 'harvard',\n",
       " 'princeton',\n",
       " 'stanford',\n",
       " 'uchicago|university of chicago',\n",
       " 'yale']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 illinois 1.60760455609\n",
      "5 article edited 1.61612137703\n",
      "5 law lecture 1.62705708839\n",
      "5 uchifor15 1.64760488503\n",
      "5 50 million 1.68095713321\n",
      "5 science video 1.68217645177\n",
      "5 wikipedia article 1.69183453514\n",
      "5 booth business 1.70254015412\n",
      "5 chicago job 1.77283623138\n",
      "5 chicago apply 1.82772342086\n",
      "5 maroon 1.83595616982\n",
      "5 linguistics 1.87206687573\n",
      "5 trauma center 2.02915498209\n",
      "5 loyola 2.12982943114\n",
      "5 medicine 2.18571427071\n",
      "5 booth 2.77967844237\n",
      "5 berniesanders 2.98249876268\n",
      "5 trauma 3.06574456913\n",
      "5 bernie 3.22293190623\n",
      "5 chicago 5.04712841451\n"
     ]
    }
   ],
   "source": [
    "most_informative_feature_for_class(tfidf_vectorizer,mclf2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2 Retweet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rt @tbhjuststop: \"bill gates was a drop out\"  ...\n",
       "1    rt @longhornnetwork: empress davenport's caree...\n",
       "2    rt @worldstarfunny: \"bill gates was a drop out...\n",
       "3    rt @thefunnyteens: \"bill gates was a drop out\"...\n",
       "4    rt @texaswbb: final score: no. 5 texas 77, no....\n",
       "5    rt @worldstarfunny: \"bill gates was a drop out...\n",
       "6    rt @clemsonmsoccer: halftime ||  1, #clemson 0...\n",
       "7    rt @longhornnetwork: empress davenport's caree...\n",
       "8    rt @antijokeapple: \"bill gates was a drop out\"...\n",
       "9    rt @ingram1738: \"bill gates was a drop out\"  o...\n",
       "Name: t_text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['t_text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['t_text']=df2['t_text'].str.replace(r'(rt @\\w+: )', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92311"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2[\"rt_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove duplicated tweets\n",
    "dff2=df2.iloc[df2.groupby(['rt_id']).apply(lambda x: x['rt_retweet_n'].idxmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_id', 't_lang', 't_created_at', 't_text', 't_retweet_n',\n",
       "       't_favorite_n', 'u_screen_name', 'u_name', 'u_location',\n",
       "       'u_description', 'u_follower_n', 'u_friend_n', 'u_listed_n',\n",
       "       'u_favorite_n', 'u_statuse_n', 'u_created_at', 'u_time_zone', 'rt_id',\n",
       "       'rt_created_at', 'rt_retweet_n', 'rt_favorite_n', 'ru_screen_name',\n",
       "       'ru_name', 'ru_location', 'ru_description', 'ru_follower_n',\n",
       "       'ru_friend_n', 'ru_listed_n', 'ru_favorite_n', 'ru_statuse_n',\n",
       "       'ru_created_at', 'ru_time_zone', 'uchicago|university of chicago',\n",
       "       'harvard', 'stanford', 'princeton', 'columbia university', 'yale',\n",
       "       'text', 'sum', 'uni'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_id</th>\n",
       "      <th>t_retweet_n</th>\n",
       "      <th>t_favorite_n</th>\n",
       "      <th>u_follower_n</th>\n",
       "      <th>u_friend_n</th>\n",
       "      <th>u_listed_n</th>\n",
       "      <th>u_favorite_n</th>\n",
       "      <th>u_statuse_n</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_retweet_n</th>\n",
       "      <th>...</th>\n",
       "      <th>ru_listed_n</th>\n",
       "      <th>ru_favorite_n</th>\n",
       "      <th>ru_statuse_n</th>\n",
       "      <th>uchicago|university of chicago</th>\n",
       "      <th>harvard</th>\n",
       "      <th>stanford</th>\n",
       "      <th>princeton</th>\n",
       "      <th>columbia university</th>\n",
       "      <th>yale</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6.864001e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2859.031509</td>\n",
       "      <td>2296.647595</td>\n",
       "      <td>106.976783</td>\n",
       "      <td>8155.116086</td>\n",
       "      <td>35133.319237</td>\n",
       "      <td>6.828145e+17</td>\n",
       "      <td>12.341625</td>\n",
       "      <td>...</td>\n",
       "      <td>393.748756</td>\n",
       "      <td>5098.929519</td>\n",
       "      <td>42182.115257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>6.848190e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3003.583646</td>\n",
       "      <td>1664.290981</td>\n",
       "      <td>128.162013</td>\n",
       "      <td>7069.695224</td>\n",
       "      <td>30057.332568</td>\n",
       "      <td>6.813406e+17</td>\n",
       "      <td>28.242892</td>\n",
       "      <td>...</td>\n",
       "      <td>777.306000</td>\n",
       "      <td>4886.339019</td>\n",
       "      <td>38811.732604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>6.856955e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2591.539266</td>\n",
       "      <td>1152.405543</td>\n",
       "      <td>91.941296</td>\n",
       "      <td>7802.576347</td>\n",
       "      <td>27966.467369</td>\n",
       "      <td>6.822321e+17</td>\n",
       "      <td>9.962763</td>\n",
       "      <td>...</td>\n",
       "      <td>436.789383</td>\n",
       "      <td>3608.348556</td>\n",
       "      <td>31766.264715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>6.816808e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2960.770901</td>\n",
       "      <td>1757.409539</td>\n",
       "      <td>164.733189</td>\n",
       "      <td>7360.971851</td>\n",
       "      <td>32100.484121</td>\n",
       "      <td>6.791927e+17</td>\n",
       "      <td>13.198905</td>\n",
       "      <td>...</td>\n",
       "      <td>773.804403</td>\n",
       "      <td>3606.178245</td>\n",
       "      <td>33972.268345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.857869e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2202.521459</td>\n",
       "      <td>1632.825912</td>\n",
       "      <td>109.020655</td>\n",
       "      <td>5696.934549</td>\n",
       "      <td>27673.657725</td>\n",
       "      <td>6.837981e+17</td>\n",
       "      <td>7.989539</td>\n",
       "      <td>...</td>\n",
       "      <td>647.086910</td>\n",
       "      <td>3206.501609</td>\n",
       "      <td>30585.192597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>6.790361e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2657.738073</td>\n",
       "      <td>2182.329676</td>\n",
       "      <td>112.645515</td>\n",
       "      <td>8601.097805</td>\n",
       "      <td>39144.987595</td>\n",
       "      <td>6.759346e+17</td>\n",
       "      <td>12.412691</td>\n",
       "      <td>...</td>\n",
       "      <td>521.112118</td>\n",
       "      <td>6610.842557</td>\n",
       "      <td>56019.101145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_id  t_retweet_n  t_favorite_n  u_follower_n   u_friend_n  \\\n",
       "uni                                                                       \n",
       "1.0  6.864001e+17          0.0           0.0   2859.031509  2296.647595   \n",
       "2.0  6.848190e+17          0.0           0.0   3003.583646  1664.290981   \n",
       "3.0  6.856955e+17          0.0           0.0   2591.539266  1152.405543   \n",
       "4.0  6.816808e+17          0.0           0.0   2960.770901  1757.409539   \n",
       "5.0  6.857869e+17          0.0           0.0   2202.521459  1632.825912   \n",
       "6.0  6.790361e+17          0.0           0.0   2657.738073  2182.329676   \n",
       "\n",
       "     u_listed_n  u_favorite_n   u_statuse_n         rt_id  rt_retweet_n ...   \\\n",
       "uni                                                                     ...    \n",
       "1.0  106.976783   8155.116086  35133.319237  6.828145e+17     12.341625 ...    \n",
       "2.0  128.162013   7069.695224  30057.332568  6.813406e+17     28.242892 ...    \n",
       "3.0   91.941296   7802.576347  27966.467369  6.822321e+17      9.962763 ...    \n",
       "4.0  164.733189   7360.971851  32100.484121  6.791927e+17     13.198905 ...    \n",
       "5.0  109.020655   5696.934549  27673.657725  6.837981e+17      7.989539 ...    \n",
       "6.0  112.645515   8601.097805  39144.987595  6.759346e+17     12.412691 ...    \n",
       "\n",
       "     ru_listed_n  ru_favorite_n  ru_statuse_n  uchicago|university of chicago  \\\n",
       "uni                                                                             \n",
       "1.0   393.748756    5098.929519  42182.115257                             0.0   \n",
       "2.0   777.306000    4886.339019  38811.732604                             0.0   \n",
       "3.0   436.789383    3608.348556  31766.264715                             0.0   \n",
       "4.0   773.804403    3606.178245  33972.268345                             0.0   \n",
       "5.0   647.086910    3206.501609  30585.192597                             1.0   \n",
       "6.0   521.112118    6610.842557  56019.101145                             0.0   \n",
       "\n",
       "     harvard  stanford  princeton  columbia university  yale  sum  \n",
       "uni                                                                \n",
       "1.0      0.0       0.0        0.0                  1.0   0.0  1.0  \n",
       "2.0      1.0       0.0        0.0                  0.0   0.0  1.0  \n",
       "3.0      0.0       0.0        1.0                  0.0   0.0  1.0  \n",
       "4.0      0.0       1.0        0.0                  0.0   0.0  1.0  \n",
       "5.0      0.0       0.0        0.0                  0.0   0.0  1.0  \n",
       "6.0      0.0       0.0        0.0                  0.0   1.0  1.0  \n",
       "\n",
       "[6 rows x 23 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff2.groupby(['uni']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff2[\"rt_retweet_n\"].quantile(.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#I use the top 20% as division point, which is 6 in our case\n",
    "dff2[\"rt_retweet_n2\"]=dff2[\"rt_retweet_n\"].apply(lambda x: 0 if x < 6 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(dff2[\"t_text\"], dff2[\"rt_retweet_n2\"], test_size=12177, random_state=42, stratify=dff2[\"rt_retweet_n2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63910\n",
       "1    16224\n",
       "Name: rt_retweet_n2, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9712\n",
       "1    2465\n",
       "Name: rt_retweet_n2, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 12 ms, total: 22.3 s\n",
      "Wall time: 22.3 s\n",
      "(80134, 48029)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=3, tokenizer=tokenize_lemmatize, stop_words='english', ngram_range=(1,2))\n",
    "%time vectors_train2 = tfidf_vectorizer.fit_transform(X_train2) #fit the vectorizer to tweets\n",
    "print(vectors_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors_test2 = tfidf_vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(vectors_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(vectors_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2=clf.predict(vectors_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsdg2=clf.predict(vectors_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.797158577646\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.797158577646\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test2, predsdg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.88      9712\n",
      "          1       0.50      0.21      0.30      2465\n",
      "\n",
      "avg / total       0.76      0.80      0.76     12177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, predsdg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=20):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "    for coef, feat in topn_class1:\n",
    "        print (class_labels[0], coef, feat)\n",
    "    print()\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.26922691045 gate dropped\n",
      "0 -0.229490411933 im blessed\n",
      "0 -0.204454835528 retweeted\n",
      "0 -0.190214796433 dailycaller\n",
      "0 -0.184530337476 announce accepted\n",
      "0 -0.179282606878 williams lead\n",
      "0 -0.174733710563 cofounder donates\n",
      "0 -0.168813076491 say handcuffed\n",
      "0 -0.165820531484 universit\n",
      "0 -0.164289268924 denied tenure\n",
      "0 -0.160990150644 hcilabs analyticsedge\n",
      "0 -0.160769613558 sta\n",
      "0 -0.159863450186 happy announce\n",
      "0 -0.158152464834 making career\n",
      "0 -0.157055066633 added\n",
      "0 -0.156689411296 hcilabs\n",
      "0 -0.155948108012 news\n",
      "0 -0.155218757735 ich2016 ikamalhaasan\n",
      "0 -0.1539678973 biz\n",
      "0 -0.152844927038 announce new\n",
      "\n",
      "1 1.9378456773 denied\n",
      "1 1.60520860034 genre\n",
      "1 1.43806026809 politicalscience\n",
      "1 1.36209264506 continuing study\n",
      "1 1.31135926666 receive offer\n",
      "1 1.23225379916 linguistics\n",
      "1 1.09207326198 blessed receive\n",
      "1 1.04962459393 continuing\n",
      "1 1.04073442704 genetics\n",
      "1 1.02896531231 study program\n",
      "1 1.01896314665 at2015\n",
      "1 1.01823170525 intensive reading\n",
      "1 0.99901189477 ecology\n",
      "1 0.961922667146 leader seminar\n",
      "1 0.938343803494 received offer\n",
      "1 0.896744864744 yeah dropped\n",
      "1 0.882673489109 grade intensive\n",
      "1 0.872652257201 entrepreneurial thought\n",
      "1 0.858843136751 dropped 11th\n",
      "1 0.841586000791 gate drop\n"
     ]
    }
   ],
   "source": [
    "most_informative_feature_for_binary_classification(tfidf_vectorizer,clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the features \"dropped 11th\" are related to Bill Gates story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @hahahuntr: got denied from harvard :( http://t.co/vighyu6pln\n",
      "rt @chilljordan: i got accepted to harvard!!!!!!!!!!😄😱👏🎓🇺🇸 http://t.co/gq7kkgbr\n",
      "rt @drvgvisual: \"bill gates was a drop out\"  yeah but he dropped out of harvard not 11th grade intensive reading\n",
      "rt @analytics_edge: stanford to host 100-year study on artificial intelligence - http://t.co/oqjfwxu38s  #ai #analytics\n",
      "rt @nohoesnextdoor: can't avoid a curve in 2015  you either too short, too nice, not an nba player, not a harvard graduate, or you care too…\n",
      "rt @yaboybillnye: a recent harvard study found that lamborghini mercy does indeed make your chick so thirsty\n",
      "rt @worldstarfunny: got denied from harvard :( http://t.co/wbaf14tu1i\n",
      "rt @manners16: \"bill gates was a dropout!\"  yeah he dropped out of harvard not btec health &amp; beauty\n",
      "rt @jlgoodmusic: i got accepted to harvard 😱 http://t.co/zfeyv3sqsi\n",
      "rt @weloverobdyrdek: got denied from harvard :( http://t.co/eyhccrjo33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for x in dff2.sort('rt_retweet_n', ascending=False)['text'][:10]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215389    rt @: what did you see #at2015? post your best...\n",
       "403603    love this campus! @ #at2015 #farmphotos #unive...\n",
       "215381    rt @: seen #at2015: virtual reality. share you...\n",
       "215376    rt @: seen #at2015: holi. share your best camp...\n",
       "181339    rt @: seen #at2015: rain (finally). share your...\n",
       "167393    rt @: as the year comes to a close, join us in...\n",
       "287296    rt @: #at2015: astronomers discovered a jupite...\n",
       "88599           rt @: seen #at2015. https://t.co/uny04xg3to\n",
       "425972    what could be more #at2015  than the student a...\n",
       "468615    rt @: said #at2015. can you identify the speak...\n",
       "381411    rt @: #at2015: @tseelig asked her students to ...\n",
       "460838    rt @: #at2015: a study on poverty delivered co...\n",
       "256187    rt @: discovered #at2015: the social cost of c...\n",
       "287714    rt @: #at2015: scholars traced the settlement ...\n",
       "287261    rt @: said #at2015. can you identify the speak...\n",
       "137660    rt @: #at2015: richard cox discussed the secre...\n",
       "88656     rt @: #at2015: adam johnson won a @nationalboo...\n",
       "455979          rt @: seen #at2015. https://t.co/1sspqtnk8r\n",
       "302046    rt @: #at2015: researchers confirmed that brai...\n",
       "302060    rt @: revealed #at2015: people are more likely...\n",
       "149574    rt @: #at2015: journalism students used data t...\n",
       "445941    rt @: seen #at2015:  jump rope, a new addition...\n",
       "418642          rt @: seen #at2015. https://t.co/txvsp6wa0a\n",
       "535971    rt @: #at2015: @dschool suggested students mig...\n",
       "527839    rt @: #at2015: @potus barack obama met with st...\n",
       "156544    rt @: #at2015: research suggested companies ta...\n",
       "535338    rt @: said #at2015: \"it's imperative that we d...\n",
       "469132    .@biz #at2015: @biz prof. lindred greer explai...\n",
       "Name: t_text, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#at2015 is an account that gets good attentions\n",
    "dff2[dff2.t_text.str.contains('at2015')]['t_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['polarity'] = df.apply(lambda x: TextBlob(x['t_text']).sentiment.polarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['subjectivity'] = df.apply(lambda x: TextBlob(x['t_text']).sentiment.subjectivity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_retweet_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_favorite_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_follower_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_friend_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">columbia university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yale</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">polarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>685475114488691328</td>\n",
       "      <td>8131</td>\n",
       "      <td>0</td>\n",
       "      <td>8131</td>\n",
       "      <td>0</td>\n",
       "      <td>8131</td>\n",
       "      <td>6372.007133</td>\n",
       "      <td>8131</td>\n",
       "      <td>2439.352109</td>\n",
       "      <td>8131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8131</td>\n",
       "      <td>0.070550</td>\n",
       "      <td>8131</td>\n",
       "      <td>0.264879</td>\n",
       "      <td>8131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>684412384206726528</td>\n",
       "      <td>240992</td>\n",
       "      <td>0</td>\n",
       "      <td>240992</td>\n",
       "      <td>0</td>\n",
       "      <td>240992</td>\n",
       "      <td>9837.840372</td>\n",
       "      <td>240992</td>\n",
       "      <td>1945.875344</td>\n",
       "      <td>240992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240992</td>\n",
       "      <td>0.088566</td>\n",
       "      <td>240992</td>\n",
       "      <td>0.266650</td>\n",
       "      <td>240992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>683787674944514304</td>\n",
       "      <td>88694</td>\n",
       "      <td>0</td>\n",
       "      <td>88694</td>\n",
       "      <td>0</td>\n",
       "      <td>88694</td>\n",
       "      <td>5681.419927</td>\n",
       "      <td>88694</td>\n",
       "      <td>1469.926286</td>\n",
       "      <td>88694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88694</td>\n",
       "      <td>0.091136</td>\n",
       "      <td>88694</td>\n",
       "      <td>0.257021</td>\n",
       "      <td>88694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>679533051556261504</td>\n",
       "      <td>229106</td>\n",
       "      <td>0</td>\n",
       "      <td>229106</td>\n",
       "      <td>0</td>\n",
       "      <td>229106</td>\n",
       "      <td>7905.365303</td>\n",
       "      <td>229106</td>\n",
       "      <td>1512.250142</td>\n",
       "      <td>229106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>229106</td>\n",
       "      <td>0.098140</td>\n",
       "      <td>229106</td>\n",
       "      <td>0.279106</td>\n",
       "      <td>229106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>685108482103091456</td>\n",
       "      <td>17905</td>\n",
       "      <td>0</td>\n",
       "      <td>17905</td>\n",
       "      <td>0</td>\n",
       "      <td>17905</td>\n",
       "      <td>6831.007651</td>\n",
       "      <td>17905</td>\n",
       "      <td>1955.096509</td>\n",
       "      <td>17905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17905</td>\n",
       "      <td>0.082105</td>\n",
       "      <td>17905</td>\n",
       "      <td>0.214034</td>\n",
       "      <td>17905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>677539948777027328</td>\n",
       "      <td>16473</td>\n",
       "      <td>0</td>\n",
       "      <td>16473</td>\n",
       "      <td>0</td>\n",
       "      <td>16473</td>\n",
       "      <td>9109.990651</td>\n",
       "      <td>16473</td>\n",
       "      <td>2124.015480</td>\n",
       "      <td>16473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16473</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>16473</td>\n",
       "      <td>0.248297</td>\n",
       "      <td>16473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t_id         t_retweet_n         t_favorite_n          \\\n",
       "                   mean   count        mean   count         mean   count   \n",
       "uni                                                                        \n",
       "1.0  685475114488691328    8131           0    8131            0    8131   \n",
       "2.0  684412384206726528  240992           0  240992            0  240992   \n",
       "3.0  683787674944514304   88694           0   88694            0   88694   \n",
       "4.0  679533051556261504  229106           0  229106            0  229106   \n",
       "5.0  685108482103091456   17905           0   17905            0   17905   \n",
       "6.0  677539948777027328   16473           0   16473            0   16473   \n",
       "\n",
       "    u_follower_n           u_friend_n           ...   columbia university  \\\n",
       "            mean   count         mean   count   ...                  mean   \n",
       "uni                                             ...                         \n",
       "1.0  6372.007133    8131  2439.352109    8131   ...                   1.0   \n",
       "2.0  9837.840372  240992  1945.875344  240992   ...                   0.0   \n",
       "3.0  5681.419927   88694  1469.926286   88694   ...                   0.0   \n",
       "4.0  7905.365303  229106  1512.250142  229106   ...                   0.0   \n",
       "5.0  6831.007651   17905  1955.096509   17905   ...                   0.0   \n",
       "6.0  9109.990651   16473  2124.015480   16473   ...                   0.0   \n",
       "\n",
       "            yale          sum          polarity         subjectivity          \n",
       "      count mean   count mean   count      mean   count         mean   count  \n",
       "uni                                                                           \n",
       "1.0    8131  0.0    8131  1.0    8131  0.070550    8131     0.264879    8131  \n",
       "2.0  240992  0.0  240992  1.0  240992  0.088566  240992     0.266650  240992  \n",
       "3.0   88694  0.0   88694  1.0   88694  0.091136   88694     0.257021   88694  \n",
       "4.0  229106  0.0  229106  1.0  229106  0.098140  229106     0.279106  229106  \n",
       "5.0   17905  0.0   17905  1.0   17905  0.082105   17905     0.214034   17905  \n",
       "6.0   16473  1.0   16473  1.0   16473  0.062898   16473     0.248297   16473  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['uni']).agg(['mean', 'count']) #mean sentiment for each university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_retweet_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_favorite_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_follower_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_friend_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">columbia university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yale</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">polarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>675166926921513344</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5634.970588</td>\n",
       "      <td>68</td>\n",
       "      <td>1353.882353</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.042760</td>\n",
       "      <td>68</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>676453765936367232</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>1981</td>\n",
       "      <td>15352.519435</td>\n",
       "      <td>1981</td>\n",
       "      <td>1529.511358</td>\n",
       "      <td>1981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.059816</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.334305</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>683178256887795072</td>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>3975.172149</td>\n",
       "      <td>912</td>\n",
       "      <td>1569.442982</td>\n",
       "      <td>912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>912</td>\n",
       "      <td>0.056348</td>\n",
       "      <td>912</td>\n",
       "      <td>0.237491</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>682735793583931136</td>\n",
       "      <td>714</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>7473.696078</td>\n",
       "      <td>714</td>\n",
       "      <td>1157.697479</td>\n",
       "      <td>714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>714</td>\n",
       "      <td>0.196099</td>\n",
       "      <td>714</td>\n",
       "      <td>0.368628</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>681543280014180608</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>9827.163636</td>\n",
       "      <td>330</td>\n",
       "      <td>1873.321212</td>\n",
       "      <td>330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330</td>\n",
       "      <td>0.100306</td>\n",
       "      <td>330</td>\n",
       "      <td>0.315978</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>666444492925387520</td>\n",
       "      <td>1521</td>\n",
       "      <td>0</td>\n",
       "      <td>1521</td>\n",
       "      <td>0</td>\n",
       "      <td>1521</td>\n",
       "      <td>5053.733070</td>\n",
       "      <td>1521</td>\n",
       "      <td>1971.953978</td>\n",
       "      <td>1521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1521</td>\n",
       "      <td>-0.003692</td>\n",
       "      <td>1521</td>\n",
       "      <td>0.179784</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t_id       t_retweet_n       t_favorite_n        \\\n",
       "                   mean count        mean count         mean count   \n",
       "uni                                                                  \n",
       "1.0  675166926921513344    68           0    68            0    68   \n",
       "2.0  676453765936367232  1981           0  1981            0  1981   \n",
       "3.0  683178256887795072   912           0   912            0   912   \n",
       "4.0  682735793583931136   714           0   714            0   714   \n",
       "5.0  681543280014180608   330           0   330            0   330   \n",
       "6.0  666444492925387520  1521           0  1521            0  1521   \n",
       "\n",
       "     u_follower_n         u_friend_n        ...  columbia university        \\\n",
       "             mean count         mean count  ...                 mean count   \n",
       "uni                                         ...                              \n",
       "1.0   5634.970588    68  1353.882353    68  ...                  1.0    68   \n",
       "2.0  15352.519435  1981  1529.511358  1981  ...                  0.0  1981   \n",
       "3.0   3975.172149   912  1569.442982   912  ...                  0.0   912   \n",
       "4.0   7473.696078   714  1157.697479   714  ...                  0.0   714   \n",
       "5.0   9827.163636   330  1873.321212   330  ...                  0.0   330   \n",
       "6.0   5053.733070  1521  1971.953978  1521  ...                  0.0  1521   \n",
       "\n",
       "    yale        sum        polarity       subjectivity        \n",
       "    mean count mean count      mean count         mean count  \n",
       "uni                                                           \n",
       "1.0  0.0    68  1.0    68  0.042760    68     0.242494    68  \n",
       "2.0  0.0  1981  1.0  1981  0.059816  1981     0.334305  1981  \n",
       "3.0  0.0   912  1.0   912  0.056348   912     0.237491   912  \n",
       "4.0  0.0   714  1.0   714  0.196099   714     0.368628   714  \n",
       "5.0  0.0   330  1.0   330  0.100306   330     0.315978   330  \n",
       "6.0  1.0  1521  1.0  1521 -0.003692  1521     0.179784  1521  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"t_text\"].str.contains('campus', na=False)].groupby(['uni']).agg(['mean', 'count']) #mean sentiment for each university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_retweet_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_favorite_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_follower_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_friend_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">columbia university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yale</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">polarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>676028304343455104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>721.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1217.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>691642111022870912</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>659</td>\n",
       "      <td>14791.605463</td>\n",
       "      <td>659</td>\n",
       "      <td>2018.051593</td>\n",
       "      <td>659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>659</td>\n",
       "      <td>0.114526</td>\n",
       "      <td>659</td>\n",
       "      <td>0.399744</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>691597970602674944</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>4004.065217</td>\n",
       "      <td>92</td>\n",
       "      <td>2427.586957</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.082507</td>\n",
       "      <td>92</td>\n",
       "      <td>0.119082</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>693619446026927744</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>5306.566327</td>\n",
       "      <td>392</td>\n",
       "      <td>1893.558673</td>\n",
       "      <td>392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>392</td>\n",
       "      <td>0.085828</td>\n",
       "      <td>392</td>\n",
       "      <td>0.290331</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>681957399816789376</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>667.153846</td>\n",
       "      <td>13</td>\n",
       "      <td>543.307692</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.084872</td>\n",
       "      <td>13</td>\n",
       "      <td>0.442372</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>670391649844321920</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>12786.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>9946.315789</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.240203</td>\n",
       "      <td>19</td>\n",
       "      <td>0.509318</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t_id       t_retweet_n       t_favorite_n        \\\n",
       "                   mean count        mean count         mean count   \n",
       "uni                                                                  \n",
       "1.0  676028304343455104     3           0     3            0     3   \n",
       "2.0  691642111022870912   659           0   659            0   659   \n",
       "3.0  691597970602674944    92           0    92            0    92   \n",
       "4.0  693619446026927744   392           0   392            0   392   \n",
       "5.0  681957399816789376    13           0    13            0    13   \n",
       "6.0  670391649844321920    19           0    19            0    19   \n",
       "\n",
       "     u_follower_n         u_friend_n        ...  columbia university        \\\n",
       "             mean count         mean count  ...                 mean count   \n",
       "uni                                         ...                              \n",
       "1.0    721.666667     3  1217.333333     3  ...                  1.0     3   \n",
       "2.0  14791.605463   659  2018.051593   659  ...                  0.0   659   \n",
       "3.0   4004.065217    92  2427.586957    92  ...                  0.0    92   \n",
       "4.0   5306.566327   392  1893.558673   392  ...                  0.0   392   \n",
       "5.0    667.153846    13   543.307692    13  ...                  0.0    13   \n",
       "6.0  12786.000000    19  9946.315789    19  ...                  0.0    19   \n",
       "\n",
       "    yale        sum        polarity       subjectivity        \n",
       "    mean count mean count      mean count         mean count  \n",
       "uni                                                           \n",
       "1.0  0.0     3  1.0     3 -0.200000     3     0.300000     3  \n",
       "2.0  0.0   659  1.0   659  0.114526   659     0.399744   659  \n",
       "3.0  0.0    92  1.0    92  0.082507    92     0.119082    92  \n",
       "4.0  0.0   392  1.0   392  0.085828   392     0.290331   392  \n",
       "5.0  0.0    13  1.0    13  0.084872    13     0.442372    13  \n",
       "6.0  1.0    19  1.0    19  0.240203    19     0.509318    19  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice that although columbia 'tuition' is very negaive, there are only three data points\n",
    "df[df[\"t_text\"].str.contains('tuition', na=False)].groupby(['uni']).agg(['mean', 'count']) #mean sentiment for each university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_retweet_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_favorite_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_follower_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_friend_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">columbia university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yale</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">polarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>672034897199987712</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>897.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>787.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>8</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>692803818632498432</td>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>842</td>\n",
       "      <td>12583.853919</td>\n",
       "      <td>842</td>\n",
       "      <td>1401.742280</td>\n",
       "      <td>842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>842</td>\n",
       "      <td>0.110764</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>680069994212160768</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7976.970000</td>\n",
       "      <td>100</td>\n",
       "      <td>3830.370000</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.085891</td>\n",
       "      <td>100</td>\n",
       "      <td>0.196985</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>687153885264217984</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>25757.978142</td>\n",
       "      <td>183</td>\n",
       "      <td>8608.978142</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0.038947</td>\n",
       "      <td>183</td>\n",
       "      <td>0.111391</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>690283367536355328</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>2305.452381</td>\n",
       "      <td>84</td>\n",
       "      <td>1461.654762</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.160752</td>\n",
       "      <td>84</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>681895688885844736</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1302.590909</td>\n",
       "      <td>22</td>\n",
       "      <td>625.500000</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>22</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t_id       t_retweet_n       t_favorite_n        \\\n",
       "                   mean count        mean count         mean count   \n",
       "uni                                                                  \n",
       "1.0  672034897199987712     8           0     8            0     8   \n",
       "2.0  692803818632498432   842           0   842            0   842   \n",
       "3.0  680069994212160768   100           0   100            0   100   \n",
       "4.0  687153885264217984   183           0   183            0   183   \n",
       "5.0  690283367536355328    84           0    84            0    84   \n",
       "6.0  681895688885844736    22           0    22            0    22   \n",
       "\n",
       "     u_follower_n         u_friend_n        ...  columbia university        \\\n",
       "             mean count         mean count  ...                 mean count   \n",
       "uni                                         ...                              \n",
       "1.0    897.125000     8   787.125000     8  ...                  1.0     8   \n",
       "2.0  12583.853919   842  1401.742280   842  ...                  0.0   842   \n",
       "3.0   7976.970000   100  3830.370000   100  ...                  0.0   100   \n",
       "4.0  25757.978142   183  8608.978142   183  ...                  0.0   183   \n",
       "5.0   2305.452381    84  1461.654762    84  ...                  0.0    84   \n",
       "6.0   1302.590909    22   625.500000    22  ...                  0.0    22   \n",
       "\n",
       "    yale        sum        polarity       subjectivity        \n",
       "    mean count mean count      mean count         mean count  \n",
       "uni                                                           \n",
       "1.0  0.0     8  1.0     8 -0.003527     8     0.231818     8  \n",
       "2.0  0.0   842  1.0   842  0.032676   842     0.110764   842  \n",
       "3.0  0.0   100  1.0   100  0.085891   100     0.196985   100  \n",
       "4.0  0.0   183  1.0   183  0.038947   183     0.111391   183  \n",
       "5.0  0.0    84  1.0    84  0.160752    84     0.193600    84  \n",
       "6.0  1.0    22  1.0    22 -0.002438    22     0.163388    22  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"t_text\"].str.contains('economics', na=False)].groupby(['uni']).agg(['mean', 'count']) #mean sentiment for each university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the restrictive filtering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_retweet_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">t_favorite_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_follower_n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">u_friend_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">columbia university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">yale university</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">polarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>685416355599243264</td>\n",
       "      <td>8223</td>\n",
       "      <td>0</td>\n",
       "      <td>8223</td>\n",
       "      <td>0</td>\n",
       "      <td>8223</td>\n",
       "      <td>6313.913292</td>\n",
       "      <td>8223</td>\n",
       "      <td>2427.808951</td>\n",
       "      <td>8223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8223</td>\n",
       "      <td>0.070008</td>\n",
       "      <td>8223</td>\n",
       "      <td>0.263474</td>\n",
       "      <td>8223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>682888549238076928</td>\n",
       "      <td>18881</td>\n",
       "      <td>0</td>\n",
       "      <td>18881</td>\n",
       "      <td>0</td>\n",
       "      <td>18881</td>\n",
       "      <td>12798.183412</td>\n",
       "      <td>18881</td>\n",
       "      <td>2119.127695</td>\n",
       "      <td>18881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18881</td>\n",
       "      <td>0.055430</td>\n",
       "      <td>18881</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>18881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>686024063728185344</td>\n",
       "      <td>4247</td>\n",
       "      <td>0</td>\n",
       "      <td>4247</td>\n",
       "      <td>0</td>\n",
       "      <td>4247</td>\n",
       "      <td>4558.649164</td>\n",
       "      <td>4247</td>\n",
       "      <td>2074.696727</td>\n",
       "      <td>4247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4247</td>\n",
       "      <td>0.101436</td>\n",
       "      <td>4247</td>\n",
       "      <td>0.217818</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>687814203394334336</td>\n",
       "      <td>10168</td>\n",
       "      <td>0</td>\n",
       "      <td>10168</td>\n",
       "      <td>0</td>\n",
       "      <td>10168</td>\n",
       "      <td>9649.530389</td>\n",
       "      <td>10168</td>\n",
       "      <td>4774.863297</td>\n",
       "      <td>10168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10168</td>\n",
       "      <td>0.063103</td>\n",
       "      <td>10168</td>\n",
       "      <td>0.160764</td>\n",
       "      <td>10168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>685496657531372032</td>\n",
       "      <td>10768</td>\n",
       "      <td>0</td>\n",
       "      <td>10768</td>\n",
       "      <td>0</td>\n",
       "      <td>10768</td>\n",
       "      <td>8481.140137</td>\n",
       "      <td>10768</td>\n",
       "      <td>2543.804606</td>\n",
       "      <td>10768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10768</td>\n",
       "      <td>0.062440</td>\n",
       "      <td>10768</td>\n",
       "      <td>0.165686</td>\n",
       "      <td>10768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>678894626611961728</td>\n",
       "      <td>11974</td>\n",
       "      <td>0</td>\n",
       "      <td>11974</td>\n",
       "      <td>0</td>\n",
       "      <td>11974</td>\n",
       "      <td>10199.804744</td>\n",
       "      <td>11974</td>\n",
       "      <td>2121.393102</td>\n",
       "      <td>11974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11974</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>11974</td>\n",
       "      <td>0.217862</td>\n",
       "      <td>11974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t_id        t_retweet_n        t_favorite_n         \\\n",
       "                   mean  count        mean  count         mean  count   \n",
       "uni                                                                     \n",
       "1.0  685416355599243264   8223           0   8223            0   8223   \n",
       "2.0  682888549238076928  18881           0  18881            0  18881   \n",
       "3.0  686024063728185344   4247           0   4247            0   4247   \n",
       "4.0  687814203394334336  10168           0  10168            0  10168   \n",
       "5.0  685496657531372032  10768           0  10768            0  10768   \n",
       "6.0  678894626611961728  11974           0  11974            0  11974   \n",
       "\n",
       "     u_follower_n          u_friend_n         ...   columbia university  \\\n",
       "             mean  count         mean  count  ...                  mean   \n",
       "uni                                           ...                         \n",
       "1.0   6313.913292   8223  2427.808951   8223  ...                   1.0   \n",
       "2.0  12798.183412  18881  2119.127695  18881  ...                   0.0   \n",
       "3.0   4558.649164   4247  2074.696727   4247  ...                   0.0   \n",
       "4.0   9649.530389  10168  4774.863297  10168  ...                   0.0   \n",
       "5.0   8481.140137  10768  2543.804606  10768  ...                   0.0   \n",
       "6.0  10199.804744  11974  2121.393102  11974  ...                   0.0   \n",
       "\n",
       "           yale university         sum         polarity        subjectivity  \\\n",
       "     count            mean  count mean  count      mean  count         mean   \n",
       "uni                                                                           \n",
       "1.0   8223             0.0   8223  1.0   8223  0.070008   8223     0.263474   \n",
       "2.0  18881             0.0  18881  1.0  18881  0.055430  18881     0.147392   \n",
       "3.0   4247             0.0   4247  1.0   4247  0.101436   4247     0.217818   \n",
       "4.0  10168             0.0  10168  1.0  10168  0.063103  10168     0.160764   \n",
       "5.0  10768             0.0  10768  1.0  10768  0.062440  10768     0.165686   \n",
       "6.0  11974             1.0  11974  1.0  11974  0.050447  11974     0.217862   \n",
       "\n",
       "            \n",
       "     count  \n",
       "uni         \n",
       "1.0   8223  \n",
       "2.0  18881  \n",
       "3.0   4247  \n",
       "4.0  10168  \n",
       "5.0  10768  \n",
       "6.0  11974  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['polarity'] = dft.apply(lambda x: TextBlob(x['t_text']).sentiment.polarity, axis=1)\n",
    "dft['subjectivity'] = dft.apply(lambda x: TextBlob(x['t_text']).sentiment.subjectivity, axis=1)\n",
    "dft.groupby(['uni']).agg(['mean', 'count']) #mean sentiment for each university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/sam/anaconda3/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from time import time\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UChicago tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of Tweets 17905 done in 0.014s.\n",
      "Tokenizing, removing non-informative words and lemmatizing\n",
      "Pre-processing done in 4.225s.\n",
      "Generating dictionary and corpus\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data = df[df[\"uni\"]==5]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documents = data[\"t_text\"].tolist()\n",
    "print(\"Number of Tweets\",len(documents),\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Tokenizing, removing non-informative words and lemmatizing\")\n",
    "t0 = time()\n",
    "documents = [tokenize_lemmatize(doc.lower()) for doc in documents ]\n",
    "print(\"Pre-processing done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Generating dictionary and corpus\")\n",
    "# Sort words in documents\n",
    "for doc in documents:\n",
    "    doc.sort()\n",
    "dictionary = corpora.Dictionary(documents) # Build a dictionary where for each document each word has its own id\n",
    "dictionary.compactify() \n",
    "dictionary.save('uchicago.dict') # and save the dictionary for future use\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents] # Build the corpus: vectors with occurence of each word for each document\n",
    "corpora.MmCorpus.serialize('uchicago.mm', corpus) # and save in Market Matrix format\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Running LDA with: 10  topics\n",
      "lda saved in uchicago10.lda \n",
      "Running LDA with: 20  topics\n",
      "lda saved in uchicago20.lda \n"
     ]
    }
   ],
   "source": [
    "#topic modelling: the LDA model\n",
    "from gensim import corpora, models, similarities\n",
    "print(\"Loading data\")\n",
    "# Initialize Parameters\n",
    "corpus_filename = 'uchicago.mm'\n",
    "dict_filename   = 'uchicago.dict'\n",
    "\n",
    "for n in [10,20]:\n",
    "    lda_filename    = 'uchicago'+str(n)+'.lda'\n",
    "    lda_params      = {'passes': 5, 'alpha': 'auto'}\n",
    "    # Load the corpus and Dictionary\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    print(\"Running LDA with: %s  topics\" % n)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,num_topics=n,passes=lda_params['passes'],alpha = lda_params['alpha'])\n",
    "    lda.save(lda_filename)\n",
    "    print(\"lda saved in %s \" % lda_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yale tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data = df[df[\"uni\"]==6]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documents = data[\"t_text\"].tolist()\n",
    "print(\"Number of Tweets\",len(documents),\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Tokenizing, removing non-informative words and lemmatizing\")\n",
    "t0 = time()\n",
    "documents = [tokenize_lemmatize(doc.lower()) for doc in documents ]\n",
    "print(\"Pre-processing done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Generating dictionary and corpus\")\n",
    "# Sort words in documents\n",
    "for doc in documents:\n",
    "    doc.sort()\n",
    "dictionary = corpora.Dictionary(documents) # Build a dictionary where for each document each word has its own id\n",
    "dictionary.compactify() \n",
    "dictionary.save('yale.dict') # and save the dictionary for future use\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents] # Build the corpus: vectors with occurence of each word for each document\n",
    "corpora.MmCorpus.serialize('yale.mm', corpus) # and save in Market Matrix format\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "print(\"Loading data\")\n",
    "# Initialize Parameters\n",
    "corpus_filename = 'yale.mm'\n",
    "dict_filename   = 'yale.dict'\n",
    "\n",
    "for n in [10,20]:\n",
    "    lda_filename    = 'yale'+str(n)+'.lda'\n",
    "    lda_params      = {'passes': 5, 'alpha': 'auto'}\n",
    "    # Load the corpus and Dictionary\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    print(\"Running LDA with: %s  topics\" % n)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,num_topics=n,passes=lda_params['passes'],alpha = lda_params['alpha'])\n",
    "    lda.save(lda_filename)\n",
    "    print(\"lda saved in %s \" % lda_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columbia Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of Tweets 8131 done in 0.006s.\n",
      "Tokenizing, removing non-informative words and lemmatizing\n",
      "Pre-processing done in 1.876s.\n",
      "Generating dictionary and corpus\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data = df[df[\"uni\"]==1]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documents = data[\"t_text\"].tolist()\n",
    "print(\"Number of Tweets\",len(documents),\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Tokenizing, removing non-informative words and lemmatizing\")\n",
    "t0 = time()\n",
    "documents = [tokenize_lemmatize(doc.lower()) for doc in documents ]\n",
    "print(\"Pre-processing done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Generating dictionary and corpus\")\n",
    "# Sort words in documents\n",
    "for doc in documents:\n",
    "    doc.sort()\n",
    "dictionary = corpora.Dictionary(documents) # Build a dictionary where for each document each word has its own id\n",
    "dictionary.compactify() \n",
    "dictionary.save('columbia.dict') # and save the dictionary for future use\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents] # Build the corpus: vectors with occurence of each word for each document\n",
    "corpora.MmCorpus.serialize('columbia.mm', corpus) # and save in Market Matrix format\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Running LDA with: 10  topics\n",
      "lda saved in columbia10.lda \n",
      "Running LDA with: 20  topics\n",
      "lda saved in columbia20.lda \n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "print(\"Loading data\")\n",
    "# Initialize Parameters\n",
    "corpus_filename = 'columbia.mm'\n",
    "dict_filename   = 'columbia.dict'\n",
    "\n",
    "for n in [10,20]:\n",
    "    lda_filename    = 'columbia'+str(n)+'.lda'\n",
    "    lda_params      = {'passes': 5, 'alpha': 'auto'}\n",
    "    # Load the corpus and Dictionary\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    print(\"Running LDA with: %s  topics\" % n)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,num_topics=n,passes=lda_params['passes'],alpha = lda_params['alpha'])\n",
    "    lda.save(lda_filename)\n",
    "    print(\"lda saved in %s \" % lda_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harvard Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data = df[df[\"uni\"]==2]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documents = data[\"t_text\"].tolist()\n",
    "print(\"Number of Tweets\",len(documents),\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Tokenizing, removing non-informative words and lemmatizing\")\n",
    "t0 = time()\n",
    "documents = [tokenize_lemmatize(doc.lower()) for doc in documents ]\n",
    "print(\"Pre-processing done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Generating dictionary and corpus\")\n",
    "# Sort words in documents\n",
    "for doc in documents:\n",
    "    doc.sort()\n",
    "dictionary = corpora.Dictionary(documents) # Build a dictionary where for each document each word has its own id\n",
    "dictionary.compactify() \n",
    "dictionary.save('harvard.dict') # and save the dictionary for future use\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents] # Build the corpus: vectors with occurence of each word for each document\n",
    "corpora.MmCorpus.serialize('harvard.mm', corpus) # and save in Market Matrix format\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "print(\"Loading data\")\n",
    "# Initialize Parameters\n",
    "corpus_filename = 'harvard.mm'\n",
    "dict_filename   = 'harvard.dict'\n",
    "\n",
    "for n in [10,20]:\n",
    "    lda_filename    = 'harvard'+str(n)+'.lda'\n",
    "    lda_params      = {'passes': 5, 'alpha': 'auto'}\n",
    "    # Load the corpus and Dictionary\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    print(\"Running LDA with: %s  topics\" % n)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,num_topics=n,passes=lda_params['passes'],alpha = lda_params['alpha'])\n",
    "    lda.save(lda_filename)\n",
    "    print(\"lda saved in %s \" % lda_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "data = df[df[\"uni\"]==4]\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "documents = data[\"t_text\"].tolist()\n",
    "print(\"Number of Tweets\",len(documents),\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Tokenizing, removing non-informative words and lemmatizing\")\n",
    "t0 = time()\n",
    "documents = [tokenize_lemmatize(doc.lower()) for doc in documents ]\n",
    "print(\"Pre-processing done in %0.3fs.\" % (time() - t0))\n",
    "print(\"Generating dictionary and corpus\")\n",
    "# Sort words in documents\n",
    "for doc in documents:\n",
    "    doc.sort()\n",
    "dictionary = corpora.Dictionary(documents) # Build a dictionary where for each document each word has its own id\n",
    "dictionary.compactify() \n",
    "dictionary.save('stanford.dict') # and save the dictionary for future use\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents] # Build the corpus: vectors with occurence of each word for each document\n",
    "corpora.MmCorpus.serialize('stanford.mm', corpus) # and save in Market Matrix format\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "print(\"Loading data\")\n",
    "# Initialize Parameters\n",
    "corpus_filename = 'stanford.mm'\n",
    "dict_filename   = 'stanford.dict'\n",
    "\n",
    "for n in [10,20]:\n",
    "    lda_filename    = 'stanford'+str(n)+'.lda'\n",
    "    lda_params      = {'passes': 5, 'alpha': 'auto'}\n",
    "    # Load the corpus and Dictionary\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    print(\"Running LDA with: %s  topics\" % n)\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary,num_topics=n,passes=lda_params['passes'],alpha = lda_params['alpha'])\n",
    "    lda.save(lda_filename)\n",
    "    print(\"lda saved in %s \" % lda_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
